人工智能监管应因时而变（微观） --观点--人民网 点击播报本文，约 直播间内，仿冒奥运冠军声音进行带货；社交平台上，冒用影视明星形象开展互动，欺骗网友情感；突发事件中，伪造所谓“受害者”照片并肆意传播，助推谣言扩散……随着生成式人工智能技术加速迭代，音频、视频、图像等内容生成效果日趋逼真，在拓展应用场景的同时，也带来了不容忽视的治理挑战。 截至2024年，我国生成式人工智能产品的用户规模已达2.49亿人，人工智能生成内容呈现跨平台化和跨境传播特征。同时，人工智能生成内容易于被批量篡改和重组，源头不易找，追溯难度大。违法违规的人工智能生成内容迅速蔓延，不仅侵害个体权益，也扰乱网络秩序，必须高度重视。 前不久施行的《人工智能生成合成内容标识办法》规定，对生成合成内容要添加显式标识，也要在文件元数据中添加隐式标识。这有助于实现对用户的提示警示，同时为内容溯源与责任认定提供技术保障。办法的施行，对提升我国人工智能安全治理水平具有重要意义。 党的二十届三中全会《决定》提出，“建立人工智能安全监管制度”。近年来，《中华人民共和国网络安全法》《互联网信息服务深度合成管理规定》《生成式人工智能服务管理暂行办法》等法律法规的出台，为人工智能的有效监管奠定了基础。然而，技术发展日新月异，规则具有滞后性，二者不可避免存在时间差。人工智能安全治理如何因时而变，避免“刻舟求剑”，值得深入探讨。 法治具有固根本、稳预期、利长远的保障作用。在立法确定的治理框架下，司法通过个案裁判和司法解释细化立法原则，填补规则漏洞，能实现对技术进步的能动回应。 比如，最高人民法院2024年发布反垄断民事诉讼司法解释，对互联网平台通过人工智能等技术手段排除、限制竞争的行为予以依法规制。实践证明，充分发挥司法职能作用，在明确行为性质、划分责任义务等方面完善规则制度，才能有效抑制技术发展可能产生的负面影响，确保“智能向善”。 技术每前进一步，治理就要跟进一步，但过度监管又会扼杀创新活力。对人工智能的治理与监管，必须统筹发展和安全，既明确相关主体行为边界，也为创新与探索留足空间。 比如，北京建立人工智能监管沙盒机制，该机制探索弱版权保护政策和风险补偿规则，降低数据安全隐患，减少数据流通中的合规成本，有助于加快推动人工智能产业化应用。这启示我们，在风险可控的前提下，对经营主体开展审慎监管和柔性治理，给予实验性项目适当容错空间，有助于破解一放就乱、一管就死的治理困局，在规范中释放产业发展活力。 习近平总书记强调，“要把握人工智能发展趋势和规律，加紧制定完善相关法律法规、政策制度、应用规范、伦理准则”。人工智能安全治理，不是简单的“管住就行”，而是要让技术在制度的“土壤”里更为茁壮地生长。 面向未来，唯有完善规则体系、强化伦理约束、提升治理效能，方能推动人工智能更好赋能千行百业，让广大人民共享技术发展带来的福祉。 《 人民日报 》（ 2025年10月16日 05 版） 分享让更多人看到 人民日报社概况| 关于人民网| 报社招聘| 招聘英才| 广告服务| 合作加盟| 版权服务| 数据服务| 网站声明| 网站律师| 信息保护| 联系我们 人民日报违法和不良信息举报电话：010-65363263 举报邮箱：jubao@people.cn 人民网服务邮箱：kf@people.cn 违法和不良信息举报电话：010-65363636 举报邮箱：rmwjubao@people.cn 互联网新闻信息服务许可证10120170001 | 增值电信业务经营许可证B1-20060139 | 广播电视节目制作经营许可证（广媒）字第172号 | 京ICP备12004265号-13 信息网络传播视听节目许可证0104065 | 网络文化经营许可证 京网文[2023]4961-141号 | 网络出版服务许可证（京）字121号 | 京ICP证000006号 | 京公网安备11000002000008号 人 民 网 股 份 有 限 公 司 版 权 所 有 ，未 经 书 面 授 权 禁 止 使 用 Copyright © 1997-2025 by www.people.com.cn. all rights reserved 